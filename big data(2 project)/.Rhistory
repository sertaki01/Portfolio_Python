write('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', file = "~/.Renviron", append = TRUE)
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
install.packages("demo.csv")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
force(acf)
force(contr.helmert)
View(R.version)
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
R.version
refresh
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
install.packages("datasets.load")
library(datasets.load)
library(data.table)
library(datawizard)
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
detach("package:datasets", unload = TRUE)
detach("package:datawizard", unload = TRUE)
detach("package:datasets.load", unload = TRUE)
detach("package:data.table", unload = TRUE)
source("~/.active-rstudio-document")
load("C:/Users/admin/Downloads/csv_0.5.3.tar.gz")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
library(stats4, lib.loc = "C:/Program Files/R/R-4.3.1/library")
source("~/.active-rstudio-document")
library(readxl)
datasets_Ex_Rout <- read_excel("C:/Program Files/R/R-4.3.1/tests/Examples/datasets-Ex.Rout.save")
View(read.csv)
View(read.csv)
force(read.csv2)
force(write.csv)
force(write.csv2)
View(read.csv)
View(read.csv)
View(read.csv)
View(read.csv2)
View(write.csv)
View(write.table)
source("~/.active-rstudio-document")
library(readxl)
data_read_csv_demo <- read_excel("data<-read.csv(\"demo.csv\", sep=\",\", header=T)")
setwd("C:\Users\admin\OneDrive\Υπολογιστής\special topics in business economics")
data= read.delim2(""CPS_85_Wages.txt.crdownload"")
df=read.table("CPS_85_Wages.txt.crdownload",header = FALSE,sep ="" )
df=read.table("CPS_85_Wages.txt",header = FALSE,sep ="" )
df=read.table(""CPS_85_Wages.txt.crdownload"",header = TRUE,sep ="" )
install.packages("AER")
data("CPS1985")
data("CPS1985")
setwd("C:\Users\admin\OneDrive\Υπολογιστής\special topics in business economics")
df<-read.table(""CPS_85_Wages.txt""),dec=".",sep="\t" header=False,colnames=("EDUCATION","SOUTH","SEX","EXPERIENCE","UNION","WAGE","AGE","RACE","OCCUPATION","SECTOR,MARR")
df<-read.table(""CPS_85_Wages.txt""),dec=".",sep="\t" header=False,stringsAsFactors=True,colnames=("EDUCATION","SOUTH","SEX","EXPERIENCE","UNION","WAGE","AGE","RACE","OCCUPATION","SECTOR,MARR")
CPS_85_Wages.txt<-read.delim2(""CPS_85_Wages.txt""),dec=".",sep="\t" header=False,stringsAsFactors=True,colnames=("EDUCATION","SOUTH","SEX","EXPERIENCE","UNION","WAGE","AGE","RACE","OCCUPATION","SECTOR,MARR")
CPS_85_Wages_txt<-read.delim2(""CPS_85_Wages.txt""),dec=".",sep="\t" header=False,stringsAsFactors=True,colnames=("EDUCATION","SOUTH","SEX","EXPERIENCE","UNION","WAGE","AGE","RACE","OCCUPATION","SECTOR,MARR")
CPS_85_Wages_txt<-read.delim2("CPS_85_Wages.txt")
setwd("C:\Users\admin\OneDrive\Υπολογιστής\special topics in business economics")
CPS_85_Wages_txt<-read.delim2("CPS_85_Wages.txt")
setwd("C:\Users\admin\OneDrive\Υπολογιστής\special topics in business economics")
CPS_85_Wages <- read.table("C:/Users/admin/OneDrive/Υπολογιστής/special topics in business economics/CPS_85_Wages.txt", header=TRUE, quote="\"")
View(CPS_85_Wages)
# Subject 4 (1)
# Deletes all variables located in the working environment.
rm(list = ls())
# Deletes all the plots that have been created.
graphics.off()
# Set working directory.
setwd("C:\\Users\\admin\\OneDrive\\Υπολογιστής\\big data(2 project)")
# Read the Mushroom dataset.
mushroom_data<-read.table("agaricus-lepiota.data",header = FALSE,sep = ",")
# Adjust the column names.
colnames(mushroom_data)<-c("poisonous","cap-shape","cap-surface","cap-color","bruises","odor","gill-attachment","gill-spacing","gill-size","gill-color","stalk-shape","stalk-root","stalk-surface-above-ring","stalk-surface-below-ring","stalk-color-above-ring","stalk-color-below-ring","veil-type","veil-color","ring-number","ring-type","spore-print-color","population","habitat")
# Shows first few rows.
head(mushroom_data)
# Shows the last few rows.
tail(mushroom_data)
# Structure.
str(mushroom_data)
# Download package.
install.packages("rpart")
library(rpart)
install.packages("rpart.plot")
library(rpart.plot)
# Calculate the total number of question marks and NA values for the specific column.
missing_values <- sum(is.character(mushroom_data$"stalk-root") & (mushroom_data$"stalk-root" == "?" | is.na(mushroom_data$"stalk-root")))
# Print the result.
print(missing_values)
# Remove rows with missing values(?) in the "stalk-root" column.
mushroom_data <- subset(mushroom_data, mushroom_data$"stalk-root" != "?")
# Shows first few rows.
head(mushroom_data)
# Shows the last few rows.
tail(mushroom_data)
# Create training and testing sets for our model.
set.seed(8)
train = sample( 1:nrow(mushroom_data), nrow(mushroom_data)*0.8)
test = -train
training_data =mushroom_data[train,]
test_data=mushroom_data[-train,]
# Create the decision tree using the training data. We want to predict poisonous based on all other attributes of the mushroom_data dataset.
tree_model = rpart(poisonous  ~ . , data=training_data, method="class",cp=0.001 )
# Visualize the dicision tree
rpart.plot(tree_model, main="Decision Tree",fallen.leaves = TRUE, branch = 1)
# Predict the class attribute (poisonous) for the testing dataset. Apply testing dataset.
tree_predict = predict(tree_model, test_data, type="class")
# Create Confusion Matrix.
testingDataConfusionTable = table(tree_predict, test_data$poisonous)
# The table distinguishes the following four elements: True e(up left),True p (down right),False e (down left),False p (up right).
print(testingDataConfusionTable)
# We see how many variables are correctly categorized based on certain characteristics.
modelAccuracy = sum( diag(testingDataConfusionTable)/sum(testingDataConfusionTable))
# Print Accuracy of our model, This means the percentage of instances that a feature correctly classified into the correct category based on certain characteristics.
cat("Accuracy:",modelAccuracy)
# Subject 4 (2)
# Frequency table of poisonous.
frequency_table1 <- table(mushroom_data$poisonous[1:30])
# Print frequency table of poisonous.
print(frequency_table1)
# We created a subset with rows from 1 to 30 and columns(1,23).
subset <- mushroom_data[1:30,c(1,23)]
# Frequency table of subset.
frequency_table2 <- table(subset)
# Print frequency table of subset.
print(frequency_table2)
# Calculate the entropy before the split.
Entropy_poisonous<- function(a,b){
total<- a+b
p_a<- a/total
p_b<- b/total
if (p_a == 0) {
log_p_a <- 0
} else {
log_p_a <- log2(p_a)
}
if (p_b == 0) {
log_p_b <- 0
} else {
log_p_b <- log2(p_b)
}
entropy_before_split<- -p_a * log_p_a - p_b * log_p_b
return(entropy_before_split)
}
# Entropy before split with habit.
entropy.before.split <- Entropy_poisonous(21, 9)
print(entropy.before.split)
# Entropy_split(habitat).
Entropy_habitat<-function(a,b,c,d){
total<-a+b+c+d
na_n<-a/total
nb_n<-b/total
nc_n<-c/total
nd_n<-d/total
Entropy_split<-na_n*Entropy_poisonous(1,0)+nb_n*Entropy_poisonous(7,4)+nc_n*Entropy_poisonous(11,0)+nd_n*Entropy_poisonous(2,5)
return(Entropy_split)
}
# Entropy split(habitat).
Entropy.split<-Entropy_habitat(1,11,11,7)
# Entropy Gain from Splitting Based on Habitat.
Entropy.Gain<-entropy.before.split-Entropy.split
print(Entropy.Gain)
# subject 3 (I)
# Includes functions for Naive Bayes.
library(e1071)
# The folder that stores and retrieves files is defined.
setwd("C:\\Users\\admin\\OneDrive\\Υπολογιστής\\big data(2 project)")
# Deletes all variables located in the working environment.
rm(list = ls())
# Deletes all the plots that have been created.
graphics.off()
# Read the data from the file.
data<-read.csv("IMDBDataset.csv",header=TRUE)
# Take a quick look at the data.
head(data)
tail(data)
# we install package "stringr" for removing all characters that are not letters or numbers.
library(stringr)
# Use str_replace_all to remove special characters.
clean <- function(text) {
cleaned <- str_replace_all(text, "[^[:alnum:] ]", "")
return(cleaned)
}
data$review <- sapply(data$review, clean)
# load the dplyr package so you can apply the to_lower function.
library(dplyr)
# Apply the to_lower function at review column in the dataframe, we also use sapply that applies a given function to each element of a list .
data$review <- sapply(data$review, to_lower)
data$review <- sapply(data$review, clean)
# The to_lower function is used to transform text into lowercase(small).
to_lower<-function(text){
return(tolower(text))
}
library(dplyr)
data$review <- sapply(data$review, to_lower)
# We install package "tm",essential functions for text processing.
install.packages("tm")
library(tm)
# Function to remove stopwords(i,me,my...).
rem_stopwords <- function(text) {
words <- stopwords(kind ="english")
return(removeWords(text, words))
}
data$review <- sapply(data$review, rem_stopwords)
# We install package "SnowballC",essential function for stemming.
install.packages("SnowballC")
library(SnowballC)
# Function for stemming(To reduce words to a common form or root, we use stemming).
stem_text <- function(text) {
return(wordStem(text, language = "en"))
}
data$review <- sapply(data$review, stem_text)
head(data)
dtm <- DocumentTermMatrix(data$review)
inspect(dtm)
findFreqTerms(dtm, 5)
dtm<-removeSparseTerms(dtm,0.99745)
dtm<-removeSparseTerms(dtm,0.99745)
data_for_model <- cbind(as.data.frame(dtm_matrix), sentiment = data$sentiment)
dtm_matrix<-as.matrix(dtm)
data_for_model <- cbind(as.data.frame(dtm_matrix), sentiment = data$sentiment)
# Split into training and testing sets
train_size <- 0.8 # This line sets the proportion of the data that you want to use for training.
train_index <- sample(1:nrow(data_for_model), round(train_size * nrow(data_for_model))) # This line generates random indices for the training set.
train_data <- data_for_model[train_index, ] # This line creates the training set.
test_data <- data_for_model[-train_index, ] # This line creates the test set.
model <- naiveBayes(sentiment ~ ., data = train_data)
predictions <- predict(model, test_data)
# Evaluate the model, computes the accuracy by dividing the total number of correct predictions by the total number of instances.
conf_matrix <- table(predictions, test_data$sentiment)
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
# Print the accuracy.
cat("Accuracy:", accuracy)
# Subject 4 (1)
# Deletes all variables located in the working environment.
rm(list = ls())
# Deletes all the plots that have been created.
graphics.off()
# Set working directory.
setwd("C:\\Users\\admin\\OneDrive\\Υπολογιστής\\big data(2 project)")
# Read the Mushroom dataset.
mushroom_data<-read.table("agaricus-lepiota.data",header = FALSE,sep = ",")
# Adjust the column names.
colnames(mushroom_data)<-c("poisonous","cap-shape","cap-surface","cap-color","bruises","odor","gill-attachment","gill-spacing","gill-size","gill-color","stalk-shape","stalk-root","stalk-surface-above-ring","stalk-surface-below-ring","stalk-color-above-ring","stalk-color-below-ring","veil-type","veil-color","ring-number","ring-type","spore-print-color","population","habitat")
# Shows first few rows.
head(mushroom_data)
